{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cce5814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 4: HYBRID EXPLANATION GENERATOR\n",
      "======================================================================\n",
      "\n",
      "Loading models and data...\n",
      "✓ Loaded LSTM model from ../step1_lstm_xai/best_lstm.pt\n",
      "✓ Loaded scaler from ../step1_lstm_xai/scaler.joblib\n",
      "✓ Loaded causal graph from ../step2_causal_discovery/causal_graph.gpickle\n",
      "  Nodes: 11, Edges: 20\n",
      "✓ Loaded data from ../step2_causal_discovery/causal_discovery_data.csv: (10000, 11)\n",
      "  ⚠ Causal discovery data has only 11 columns\n",
      "  ⚠ LSTM needs 42 features\n",
      "  Loading original dataset instead...\n",
      "  ✗ Could not find dataset-labeled-anon-ip.csv\n",
      "  Will create synthetic examples instead\n",
      "\n",
      "======================================================================\n",
      "XAI COMPONENT: Feature Importance\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "CAUSAL COMPONENT: Root Cause Analysis\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "HYBRID EXPLAINER: Combining XAI + Causal\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "GENERATING DEMO EXPLANATIONS\n",
      "======================================================================\n",
      "\n",
      "⚠ No data available for demo. Creating synthetic example...\n",
      "======================================================================\n",
      "HYBRID EXPLANATION - Alert #DEMO-001\n",
      "======================================================================\n",
      "\n",
      "🎯 CLASSIFICATION\n",
      "  Prediction: Irrelevant\n",
      "  Confidence: 100.0%\n",
      "  Severity: HIGH\n",
      "\n",
      "📊 XAI ANALYSIS: What triggered this alert?\n",
      "\n",
      "  1. SignatureID\n",
      "     Value: 2001219.0000\n",
      "     Importance: 0.0000\n",
      "\n",
      "  2. SignatureMatchesPerDay\n",
      "     Value: 5000.0000\n",
      "     Importance: 0.0000\n",
      "\n",
      "  3. AlertCount\n",
      "     Value: 250.0000\n",
      "     Importance: 0.0000\n",
      "\n",
      "  4. Proto\n",
      "     Value: 6.0000\n",
      "     Importance: 0.0000\n",
      "\n",
      "  5. ExtPort\n",
      "     Value: 54321.0000\n",
      "     Importance: 0.0000\n",
      "\n",
      "🔍 CAUSAL ANALYSIS: Why/How did this happen?\n",
      "\n",
      "  Feature: SignatureID\n",
      "\n",
      "  Feature: SignatureMatchesPerDay\n",
      "\n",
      "  Feature: AlertCount\n",
      "  Root Causes: SignatureMatchesPerDay\n",
      "  Causal Chains:\n",
      "    • SignatureMatchesPerDay → AlertCount\n",
      "\n",
      "  Feature: Proto\n",
      "  Root Causes: SignatureID, SignatureMatchesPerDay\n",
      "  Causal Chains:\n",
      "    • SignatureID → Proto\n",
      "    • SignatureMatchesPerDay → Proto\n",
      "\n",
      "  Feature: ExtPort\n",
      "  Root Causes: SignatureID\n",
      "  Causal Chains:\n",
      "    • SignatureID → ExtPort\n",
      "\n",
      "  Direct Causes of Alert Classification:\n",
      "    • SCAS = 1.0000\n",
      "    • SignatureMatchesPerDay = 5000.0000\n",
      "    • Similarity = 0.8800\n",
      "    • Proto = 6.0000\n",
      "    • SignatureIDSimilarity = 0.9200\n",
      "    • ProtoSimilarity = 1.0000\n",
      "    • SignatureID = 2001219.0000\n",
      "    • IntPort = 22.0000\n",
      "\n",
      "✅ RECOMMENDED ACTIONS\n",
      "\n",
      "  Immediate Actions:\n",
      "    • High volume attack (250 alerts) - Consider rate limiting/blocking\n",
      "\n",
      "  Root Cause Mitigation:\n",
      "    • Root causes of AlertCount: SignatureMatchesPerDay\n",
      "    • Root causes of Proto: SignatureID, SignatureMatchesPerDay\n",
      "    • Root causes of ExtPort: SignatureID\n",
      "\n",
      "======================================================================\n",
      "Saved visualization to: hybrid_explanation_demo.png\n",
      "\n",
      "======================================================================\n",
      "STEP 4 COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Generated files:\n",
      "  - hybrid_explanation_*.json (structured data)\n",
      "  - hybrid_explanation_*.png (visualizations)\n",
      "\n",
      "Next: Step 5 - Evaluation (user study + quantitative metrics)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Hybrid Explanation Generator\n",
    "# Combines XAI (what) + Causal (why/how) for actionable NIDS alert explanations\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 4: HYBRID EXPLANATION GENERATOR\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ==================== CONFIGURATION ====================\n",
    "LSTM_MODEL_PATH = '../step1_lstm_xai/best_lstm.pt'\n",
    "SCALER_PATH = '../step1_lstm_xai/scaler.joblib'\n",
    "CAUSAL_GRAPH_PATH = '../step2_causal_discovery/causal_graph.gpickle'\n",
    "DATA_PATH = '../step2_causal_discovery/causal_discovery_data.csv'\n",
    "\n",
    "# Feature names - MUST match the 42 features used in Step 1 LSTM training\n",
    "# These are ALL features from the original dataset (excluding dropped columns)\n",
    "FEATURE_NAMES = [\n",
    "    'SignatureID', 'SignatureMatchesPerDay', 'AlertCount', 'Proto',\n",
    "    'ExtPort', 'IntPort', 'Similarity', 'SCAS', 'AppProtoSimilarity',\n",
    "    'DnsRrnameSimilarity', 'DnsRrtypeSimilarity', 'EmailFromSimilarity',\n",
    "    'EmailStatusSimilarity', 'EmailToSimilarity', 'ExtIPSimilarity',\n",
    "    'ExtPortSimilarity', 'HttpContentTypeSimilarity', 'HttpHostnameSimilarity',\n",
    "    'HttpMethodSimilarity', 'HttpProtocolSimilarity', 'HttpRequestBodySimilarity',\n",
    "    'HttpResponseBodySimilarity', 'HttpStatusSimilarity', 'HttpUrlSimilarity',\n",
    "    'HttpUserAgentSimilarity', 'IntIPSimilarity', 'IntPortSimilarity',\n",
    "    'ProtoSimilarity', 'SignatureIDSimilarity', 'SmtpHeloSimilarity',\n",
    "    'SmtpMailFromSimilarity', 'SmtpRcptToSimilarity', 'SshClientProtoSimilarity',\n",
    "    'SshClientSoftwareSimilarity', 'SshServerProtoSimilarity',\n",
    "    'SshServerSoftwareSimilarity', 'TlsFingerprintSimilarity',\n",
    "    'TlsIssuerDnSimilarity', 'TlsJa3hashSimilarity', 'TlsSniSimilarity',\n",
    "    'TlsSubjectSimilarity', 'TlsVersionSimilarity'\n",
    "]\n",
    "\n",
    "# Subset used in causal discovery (Step 2) - for causal analysis only\n",
    "CAUSAL_FEATURES = [\n",
    "    'SignatureMatchesPerDay', 'Similarity', 'SCAS', 'SignatureID',\n",
    "    'SignatureIDSimilarity', 'Proto', 'AlertCount', 'IntPort', \n",
    "    'ExtPort', 'ProtoSimilarity'\n",
    "]\n",
    "\n",
    "# ==================== LOAD MODELS AND DATA ====================\n",
    "print(\"\\nLoading models and data...\")\n",
    "\n",
    "# Load LSTM model architecture (must match Step 1)\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128, num_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]\n",
    "        return self.fc(out)\n",
    "\n",
    "# Load trained model\n",
    "device = torch.device('cpu')\n",
    "input_size = len(FEATURE_NAMES)\n",
    "model = LSTMClassifier(input_size=input_size).to(device)\n",
    "\n",
    "if Path(LSTM_MODEL_PATH).exists():\n",
    "    model.load_state_dict(torch.load(LSTM_MODEL_PATH, map_location=device))\n",
    "    model.eval()\n",
    "    print(f\"✓ Loaded LSTM model from {LSTM_MODEL_PATH}\")\n",
    "else:\n",
    "    print(f\"⚠ Warning: {LSTM_MODEL_PATH} not found. Using untrained model.\")\n",
    "\n",
    "# Load scaler\n",
    "if Path(SCALER_PATH).exists():\n",
    "    scaler = joblib.load(SCALER_PATH)\n",
    "    print(f\"✓ Loaded scaler from {SCALER_PATH}\")\n",
    "else:\n",
    "    print(f\"⚠ Warning: {SCALER_PATH} not found. Scaling may be incorrect.\")\n",
    "    scaler = None\n",
    "\n",
    "# Load causal graph\n",
    "if Path(CAUSAL_GRAPH_PATH).exists():\n",
    "    causal_graph = nx.read_gpickle(CAUSAL_GRAPH_PATH)\n",
    "    print(f\"✓ Loaded causal graph from {CAUSAL_GRAPH_PATH}\")\n",
    "    print(f\"  Nodes: {causal_graph.number_of_nodes()}, Edges: {causal_graph.number_of_edges()}\")\n",
    "else:\n",
    "    print(f\"⚠ Warning: {CAUSAL_GRAPH_PATH} not found. Creating empty graph.\")\n",
    "    causal_graph = nx.DiGraph()\n",
    "\n",
    "# Load sample data for testing\n",
    "if Path(DATA_PATH).exists():\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(f\"✓ Loaded data from {DATA_PATH}: {df.shape}\")\n",
    "    \n",
    "    # Check if we need to load the full original dataset instead\n",
    "    if len(df.columns) < len(FEATURE_NAMES):\n",
    "        print(f\"  ⚠ Causal discovery data has only {len(df.columns)} columns\")\n",
    "        print(f\"  ⚠ LSTM needs {len(FEATURE_NAMES)} features\")\n",
    "        print(f\"  Loading original dataset instead...\")\n",
    "        \n",
    "        # Try to load original dataset\n",
    "        original_data_path = 'dataset-labeled-anon-ip.csv'\n",
    "        if Path(original_data_path).exists():\n",
    "            df_full = pd.read_csv(original_data_path)\n",
    "            print(f\"  ✓ Loaded full dataset: {df_full.shape}\")\n",
    "            \n",
    "            # Drop non-feature columns\n",
    "            drop_cols = ['SignatureText', 'Timestamp', 'ExtIP', 'IntIP']\n",
    "            for col in drop_cols:\n",
    "                if col in df_full.columns:\n",
    "                    df_full = df_full.drop(columns=[col])\n",
    "            \n",
    "            # Use full dataset\n",
    "            df = df_full\n",
    "            print(f\"  ✓ Using full dataset with {len(df.columns)} features\")\n",
    "        else:\n",
    "            print(f\"  ✗ Could not find {original_data_path}\")\n",
    "            print(f\"  Will create synthetic examples instead\")\n",
    "            df = None\n",
    "else:\n",
    "    print(f\"⚠ Warning: {DATA_PATH} not found.\")\n",
    "    df = None\n",
    "\n",
    "# ==================== XAI COMPONENT ====================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"XAI COMPONENT: Feature Importance\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def compute_deeplift_attribution(model, alert_tensor, baseline=None):\n",
    "    \"\"\"\n",
    "    Compute DeepLIFT attributions for a single alert\n",
    "    \n",
    "    Args:\n",
    "        model: LSTM model\n",
    "        alert_tensor: torch.Tensor of shape (1, 1, num_features)\n",
    "        baseline: Baseline for comparison (default: zeros)\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of feature attributions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from captum.attr import DeepLift\n",
    "        \n",
    "        if baseline is None:\n",
    "            baseline = torch.zeros_like(alert_tensor)\n",
    "        \n",
    "        dl = DeepLift(model)\n",
    "        \n",
    "        # Get model prediction\n",
    "        with torch.no_grad():\n",
    "            output = model(alert_tensor)\n",
    "            pred_class = output.argmax(dim=1).item()\n",
    "        \n",
    "        # Compute attributions for predicted class\n",
    "        attributions = dl.attribute(alert_tensor, baselines=baseline, target=pred_class)\n",
    "        \n",
    "        return attributions.squeeze().detach().cpu().numpy()\n",
    "    \n",
    "    except ImportError:\n",
    "        print(\"⚠ Captum not installed. Using gradient-based approximation.\")\n",
    "        return compute_gradient_attribution(model, alert_tensor)\n",
    "\n",
    "def compute_gradient_attribution(model, alert_tensor):\n",
    "    \"\"\"\n",
    "    Fallback: Simple gradient-based attribution\n",
    "    \"\"\"\n",
    "    alert_tensor.requires_grad = True\n",
    "    output = model(alert_tensor)\n",
    "    pred_class = output.argmax(dim=1).item()\n",
    "    \n",
    "    # Compute gradient\n",
    "    model.zero_grad()\n",
    "    output[0, pred_class].backward()\n",
    "    \n",
    "    gradients = alert_tensor.grad.squeeze().detach().cpu().numpy()\n",
    "    values = alert_tensor.squeeze().detach().cpu().numpy()\n",
    "    \n",
    "    # Attribution = gradient * input\n",
    "    attributions = gradients * values\n",
    "    \n",
    "    return attributions\n",
    "\n",
    "def generate_xai_explanation(model, alert_features, feature_names, top_k=5):\n",
    "    \"\"\"\n",
    "    Generate XAI explanation for an alert\n",
    "    \n",
    "    Args:\n",
    "        model: LSTM model\n",
    "        alert_features: numpy array of feature values\n",
    "        feature_names: list of feature names\n",
    "        top_k: number of top features to return\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with XAI results\n",
    "    \"\"\"\n",
    "    # Prepare input tensor\n",
    "    alert_tensor = torch.tensor(alert_features, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Get prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(alert_tensor)\n",
    "        probs = torch.softmax(output, dim=1)[0]\n",
    "        pred_class = output.argmax(dim=1).item()\n",
    "        confidence = probs[pred_class].item()\n",
    "    \n",
    "    # Compute attributions\n",
    "    attributions = compute_deeplift_attribution(model, alert_tensor)\n",
    "    \n",
    "    # Combine features with their attributions\n",
    "    feature_importance = []\n",
    "    for i, (name, attr, value) in enumerate(zip(feature_names, attributions, alert_features)):\n",
    "        feature_importance.append({\n",
    "            'feature': name,\n",
    "            'importance': float(attr),\n",
    "            'value': float(value),\n",
    "            'abs_importance': float(abs(attr))\n",
    "        })\n",
    "    \n",
    "    # Sort by absolute importance\n",
    "    feature_importance.sort(key=lambda x: x['abs_importance'], reverse=True)\n",
    "    \n",
    "    return {\n",
    "        'prediction': 'Important' if pred_class == 1 else 'Irrelevant',\n",
    "        'confidence': confidence,\n",
    "        'pred_class': pred_class,\n",
    "        'top_features': feature_importance[:top_k],\n",
    "        'all_features': feature_importance\n",
    "    }\n",
    "\n",
    "# ==================== CAUSAL COMPONENT ====================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CAUSAL COMPONENT: Root Cause Analysis\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def find_root_causes(graph, target_feature):\n",
    "    \"\"\"Find all root causes (ancestors with no incoming edges) of target\"\"\"\n",
    "    if target_feature not in graph:\n",
    "        return []\n",
    "    \n",
    "    ancestors = nx.ancestors(graph, target_feature)\n",
    "    root_causes = [node for node in ancestors if graph.in_degree(node) == 0]\n",
    "    \n",
    "    return root_causes\n",
    "\n",
    "def find_causal_path(graph, source, target):\n",
    "    \"\"\"Find shortest causal path from source to target\"\"\"\n",
    "    if source not in graph or target not in graph:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        path = nx.shortest_path(graph, source, target)\n",
    "        return path\n",
    "    except nx.NetworkXNoPath:\n",
    "        return None\n",
    "\n",
    "def get_direct_causes(graph, feature):\n",
    "    \"\"\"Get direct causes (parents) of a feature\"\"\"\n",
    "    if feature not in graph:\n",
    "        return []\n",
    "    return list(graph.predecessors(feature))\n",
    "\n",
    "def analyze_causal_chain(graph, target_feature, alert_data, all_feature_names):\n",
    "    \"\"\"\n",
    "    Analyze causal chains leading to target feature\n",
    "    \n",
    "    Args:\n",
    "        graph: NetworkX causal graph (contains CAUSAL_FEATURES only)\n",
    "        target_feature: Feature to analyze (e.g., 'SCAS')\n",
    "        alert_data: Dictionary of ALL feature values (42 features)\n",
    "        all_feature_names: List of all feature names (42 features)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with causal analysis\n",
    "    \"\"\"\n",
    "    # Only analyze if feature is in the causal graph\n",
    "    if target_feature not in graph:\n",
    "        return {\n",
    "            'target': target_feature,\n",
    "            'in_graph': False,\n",
    "            'root_causes': [],\n",
    "            'causal_paths': [],\n",
    "            'direct_causes': []\n",
    "        }\n",
    "    \n",
    "    # Find root causes\n",
    "    root_causes = find_root_causes(graph, target_feature)\n",
    "    \n",
    "    # Find causal paths from each root cause\n",
    "    causal_paths = []\n",
    "    for root in root_causes:\n",
    "        path = find_causal_path(graph, root, target_feature)\n",
    "        if path:\n",
    "            # Add feature values to path\n",
    "            path_with_values = []\n",
    "            for feature in path:\n",
    "                value = alert_data.get(feature, 'N/A')\n",
    "                path_with_values.append({\n",
    "                    'feature': feature,\n",
    "                    'value': value\n",
    "                })\n",
    "            \n",
    "            causal_paths.append({\n",
    "                'root': root,\n",
    "                'path': path,\n",
    "                'path_with_values': path_with_values,\n",
    "                'length': len(path)\n",
    "            })\n",
    "    \n",
    "    # Get direct causes\n",
    "    direct_causes = get_direct_causes(graph, target_feature)\n",
    "    direct_causes_with_values = []\n",
    "    for cause in direct_causes:\n",
    "        direct_causes_with_values.append({\n",
    "            'feature': cause,\n",
    "            'value': alert_data.get(cause, 'N/A')\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        'target': target_feature,\n",
    "        'in_graph': True,\n",
    "        'root_causes': root_causes,\n",
    "        'causal_paths': causal_paths,\n",
    "        'direct_causes': direct_causes_with_values,\n",
    "        'num_paths': len(causal_paths)\n",
    "    }\n",
    "\n",
    "# ==================== HYBRID EXPLAINER ====================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HYBRID EXPLAINER: Combining XAI + Causal\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class HybridExplainer:\n",
    "    \"\"\"\n",
    "    Combines XAI and Causal Analysis for comprehensive NIDS alert explanations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, causal_graph, feature_names, scaler=None):\n",
    "        self.model = model\n",
    "        self.graph = causal_graph\n",
    "        self.feature_names = feature_names\n",
    "        self.scaler = scaler\n",
    "    \n",
    "    def explain(self, alert_data, alert_id=None):\n",
    "        \"\"\"\n",
    "        Generate hybrid explanation for a single alert\n",
    "        \n",
    "        Args:\n",
    "            alert_data: numpy array (42 features) or dict of feature values\n",
    "            alert_id: Optional alert identifier\n",
    "        \n",
    "        Returns:\n",
    "            HybridExplanation object\n",
    "        \"\"\"\n",
    "        # Convert dict to array if needed\n",
    "        if isinstance(alert_data, dict):\n",
    "            # Ensure all 42 features are present\n",
    "            alert_features = np.array([alert_data.get(f, 0) for f in self.feature_names])\n",
    "            alert_dict = alert_data\n",
    "        else:\n",
    "            alert_features = alert_data\n",
    "            # Create dict with all features\n",
    "            alert_dict = {f: v for f, v in zip(self.feature_names, alert_features)}\n",
    "        \n",
    "        # Step 1: Get LSTM prediction and XAI explanation (uses all 42 features)\n",
    "        xai_results = generate_xai_explanation(\n",
    "            self.model, \n",
    "            alert_features, \n",
    "            self.feature_names,\n",
    "            top_k=5\n",
    "        )\n",
    "        \n",
    "        # Step 2: Analyze causal chains for top XAI features\n",
    "        # Only analyze features that exist in causal graph\n",
    "        causal_analyses = []\n",
    "        for feat_info in xai_results['top_features']:\n",
    "            feature_name = feat_info['feature']\n",
    "            \n",
    "            # Only do causal analysis if feature is in causal graph\n",
    "            if feature_name in self.graph:\n",
    "                causal_analysis = analyze_causal_chain(\n",
    "                    self.graph,\n",
    "                    feature_name,\n",
    "                    alert_dict,\n",
    "                    self.feature_names\n",
    "                )\n",
    "                causal_analyses.append(causal_analysis)\n",
    "        \n",
    "        # Step 3: Analyze causal chain to Label (outcome)\n",
    "        label_causal = None\n",
    "        if 'Label' in self.graph:\n",
    "            label_causal = analyze_causal_chain(\n",
    "                self.graph,\n",
    "                'Label',\n",
    "                alert_dict,\n",
    "                self.feature_names\n",
    "            )\n",
    "        \n",
    "        # Step 4: Generate recommendations\n",
    "        recommendations = self._generate_recommendations(\n",
    "            xai_results,\n",
    "            causal_analyses,\n",
    "            alert_dict\n",
    "        )\n",
    "        \n",
    "        # Create explanation object\n",
    "        explanation = HybridExplanation(\n",
    "            alert_id=alert_id,\n",
    "            alert_data=alert_dict,\n",
    "            xai_results=xai_results,\n",
    "            causal_analyses=causal_analyses,\n",
    "            label_causal=label_causal,\n",
    "            recommendations=recommendations\n",
    "        )\n",
    "        \n",
    "        return explanation\n",
    "    \n",
    "    def _generate_recommendations(self, xai_results, causal_analyses, alert_data):\n",
    "        \"\"\"Generate actionable recommendations based on XAI and causal analysis\"\"\"\n",
    "        recommendations = {\n",
    "            'severity': 'MEDIUM',\n",
    "            'immediate_actions': [],\n",
    "            'investigation_steps': [],\n",
    "            'root_cause_mitigation': []\n",
    "        }\n",
    "        \n",
    "        # Determine severity\n",
    "        confidence = xai_results['confidence']\n",
    "        if confidence > 0.9:\n",
    "            recommendations['severity'] = 'HIGH'\n",
    "        elif confidence > 0.7:\n",
    "            recommendations['severity'] = 'MEDIUM'\n",
    "        else:\n",
    "            recommendations['severity'] = 'LOW'\n",
    "        \n",
    "        # Analyze top features for specific actions\n",
    "        top_features = xai_results['top_features']\n",
    "        \n",
    "        for feat in top_features:\n",
    "            feature = feat['feature']\n",
    "            value = feat['value']\n",
    "            \n",
    "            # SSH port targeted\n",
    "            if feature == 'IntPort' and value == 22:\n",
    "                recommendations['immediate_actions'].append(\n",
    "                    \"SSH port (22) targeted - Enable SSH hardening (key-only auth, fail2ban)\"\n",
    "                )\n",
    "            \n",
    "            # Outlier detection\n",
    "            if feature == 'SCAS' and value == 1:\n",
    "                recommendations['immediate_actions'].append(\n",
    "                    \"Outlier detected (SCAS=1) - Novel attack pattern, requires manual investigation\"\n",
    "                )\n",
    "                recommendations['investigation_steps'].append(\n",
    "                    \"Compare with historical alerts - this pattern hasn't been seen before\"\n",
    "                )\n",
    "            \n",
    "            # High signature matching\n",
    "            if feature == 'SignatureMatchesPerDay' and value > 50000:\n",
    "                recommendations['immediate_actions'].append(\n",
    "                    \"Extremely high signature match frequency - Potential coordinated campaign\"\n",
    "                )\n",
    "                recommendations['investigation_steps'].append(\n",
    "                    f\"Search for other hosts with SignatureMatchesPerDay > 50K in last 24h\"\n",
    "                )\n",
    "                recommendations['root_cause_mitigation'].append(\n",
    "                    f\"Review signature rules - {int(value)} matches/day suggests tuning needed\"\n",
    "                )\n",
    "            \n",
    "            # High similarity to known attacks\n",
    "            if feature == 'SignatureIDSimilarity' and value > 0.9:\n",
    "                recommendations['investigation_steps'].append(\n",
    "                    f\"Pattern matches known attacks (similarity={value:.2f}) - Check threat intelligence\"\n",
    "                )\n",
    "            \n",
    "            # Alert flood\n",
    "            if feature == 'AlertCount' and value > 100:\n",
    "                recommendations['immediate_actions'].append(\n",
    "                    f\"High volume attack ({int(value)} alerts) - Consider rate limiting/blocking\"\n",
    "                )\n",
    "        \n",
    "        # Add causal-based recommendations\n",
    "        for causal in causal_analyses:\n",
    "            if causal['root_causes']:\n",
    "                root_cause_str = ', '.join(causal['root_causes'])\n",
    "                recommendations['root_cause_mitigation'].append(\n",
    "                    f\"Root causes of {causal['target']}: {root_cause_str}\"\n",
    "                )\n",
    "        \n",
    "        # Default action if nothing specific\n",
    "        if not recommendations['immediate_actions']:\n",
    "            recommendations['immediate_actions'].append(\n",
    "                \"Review alert details and correlate with other security events\"\n",
    "            )\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "class HybridExplanation:\n",
    "    \"\"\"\n",
    "    Container for hybrid explanation results\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alert_id, alert_data, xai_results, causal_analyses, \n",
    "                 label_causal, recommendations):\n",
    "        self.alert_id = alert_id\n",
    "        self.alert_data = alert_data\n",
    "        self.xai = xai_results\n",
    "        self.causal = causal_analyses\n",
    "        self.label_causal = label_causal\n",
    "        self.recommendations = recommendations\n",
    "    \n",
    "    def to_dict(self):\n",
    "        \"\"\"Convert to dictionary\"\"\"\n",
    "        return {\n",
    "            'alert_id': self.alert_id,\n",
    "            'alert_data': self.alert_data,\n",
    "            'xai_analysis': self.xai,\n",
    "            'causal_analysis': self.causal,\n",
    "            'label_causal': self.label_causal,\n",
    "            'recommendations': self.recommendations\n",
    "        }\n",
    "    \n",
    "    def to_json(self, filepath=None):\n",
    "        \"\"\"Export to JSON\"\"\"\n",
    "        data = self.to_dict()\n",
    "        if filepath:\n",
    "            with open(filepath, 'w') as f:\n",
    "                json.dump(data, f, indent=2)\n",
    "            return filepath\n",
    "        else:\n",
    "            return json.dumps(data, indent=2)\n",
    "    \n",
    "    def to_text(self):\n",
    "        \"\"\"Generate natural language explanation\"\"\"\n",
    "        lines = []\n",
    "        lines.append(\"=\"*70)\n",
    "        lines.append(f\"HYBRID EXPLANATION - Alert #{self.alert_id or 'Unknown'}\")\n",
    "        lines.append(\"=\"*70)\n",
    "        lines.append(\"\")\n",
    "        \n",
    "        # Classification\n",
    "        lines.append(\"🎯 CLASSIFICATION\")\n",
    "        lines.append(f\"  Prediction: {self.xai['prediction']}\")\n",
    "        lines.append(f\"  Confidence: {self.xai['confidence']:.1%}\")\n",
    "        lines.append(f\"  Severity: {self.recommendations['severity']}\")\n",
    "        lines.append(\"\")\n",
    "        \n",
    "        # XAI Analysis\n",
    "        lines.append(\"📊 XAI ANALYSIS: What triggered this alert?\")\n",
    "        lines.append(\"\")\n",
    "        for i, feat in enumerate(self.xai['top_features'], 1):\n",
    "            lines.append(f\"  {i}. {feat['feature']}\")\n",
    "            lines.append(f\"     Value: {feat['value']:.4f}\")\n",
    "            lines.append(f\"     Importance: {feat['importance']:.4f}\")\n",
    "            lines.append(\"\")\n",
    "        \n",
    "        # Causal Analysis\n",
    "        lines.append(\"🔍 CAUSAL ANALYSIS: Why/How did this happen?\")\n",
    "        lines.append(\"\")\n",
    "        \n",
    "        for causal in self.causal:\n",
    "            if not causal['in_graph']:\n",
    "                continue\n",
    "            \n",
    "            lines.append(f\"  Feature: {causal['target']}\")\n",
    "            \n",
    "            if causal['root_causes']:\n",
    "                lines.append(f\"  Root Causes: {', '.join(causal['root_causes'])}\")\n",
    "            \n",
    "            if causal['causal_paths']:\n",
    "                lines.append(f\"  Causal Chains:\")\n",
    "                for path_info in causal['causal_paths'][:2]:  # Show top 2 paths\n",
    "                    path_str = ' → '.join(path_info['path'])\n",
    "                    lines.append(f\"    • {path_str}\")\n",
    "            \n",
    "            lines.append(\"\")\n",
    "        \n",
    "        # Label causal analysis\n",
    "        if self.label_causal and self.label_causal['in_graph']:\n",
    "            lines.append(\"  Direct Causes of Alert Classification:\")\n",
    "            for cause in self.label_causal['direct_causes']:\n",
    "                lines.append(f\"    • {cause['feature']} = {cause['value']:.4f}\")\n",
    "            lines.append(\"\")\n",
    "        \n",
    "        # Recommendations\n",
    "        lines.append(\"✅ RECOMMENDED ACTIONS\")\n",
    "        lines.append(\"\")\n",
    "        \n",
    "        if self.recommendations['immediate_actions']:\n",
    "            lines.append(\"  Immediate Actions:\")\n",
    "            for action in self.recommendations['immediate_actions']:\n",
    "                lines.append(f\"    • {action}\")\n",
    "            lines.append(\"\")\n",
    "        \n",
    "        if self.recommendations['investigation_steps']:\n",
    "            lines.append(\"  Investigation Steps:\")\n",
    "            for step in self.recommendations['investigation_steps']:\n",
    "                lines.append(f\"    • {step}\")\n",
    "            lines.append(\"\")\n",
    "        \n",
    "        if self.recommendations['root_cause_mitigation']:\n",
    "            lines.append(\"  Root Cause Mitigation:\")\n",
    "            for mitigation in self.recommendations['root_cause_mitigation']:\n",
    "                lines.append(f\"    • {mitigation}\")\n",
    "            lines.append(\"\")\n",
    "        \n",
    "        lines.append(\"=\"*70)\n",
    "        \n",
    "        return '\\n'.join(lines)\n",
    "    \n",
    "    def visualize(self, save_path=None):\n",
    "        \"\"\"Create visual explanation\"\"\"\n",
    "        fig = plt.figure(figsize=(16, 10))\n",
    "        gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "        \n",
    "        # Title\n",
    "        fig.suptitle(f'Hybrid Explanation - Alert #{self.alert_id or \"Unknown\"}', \n",
    "                     fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 1. XAI Feature Importance (top subplot)\n",
    "        ax1 = fig.add_subplot(gs[0, :])\n",
    "        top_feats = self.xai['top_features']\n",
    "        features = [f['feature'] for f in top_feats]\n",
    "        importances = [f['importance'] for f in top_feats]\n",
    "        colors = ['red' if imp > 0 else 'blue' for imp in importances]\n",
    "        \n",
    "        ax1.barh(features, importances, color=colors, alpha=0.7)\n",
    "        ax1.set_xlabel('Importance Score')\n",
    "        ax1.set_title('XAI Analysis: Top Feature Importance', fontweight='bold')\n",
    "        ax1.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "        ax1.grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        # 2. Prediction info (middle left)\n",
    "        ax2 = fig.add_subplot(gs[1, 0])\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        pred_text = f\"\"\"\n",
    "PREDICTION\n",
    "{'='*30}\n",
    "Class: {self.xai['prediction']}\n",
    "Confidence: {self.xai['confidence']:.1%}\n",
    "Severity: {self.recommendations['severity']}\n",
    "\"\"\"\n",
    "        ax2.text(0.1, 0.5, pred_text, fontsize=11, family='monospace',\n",
    "                verticalalignment='center')\n",
    "        \n",
    "        # 3. Causal paths (middle right)\n",
    "        ax3 = fig.add_subplot(gs[1, 1])\n",
    "        ax3.axis('off')\n",
    "        \n",
    "        causal_text = \"CAUSAL CHAINS\\n\" + \"=\"*30 + \"\\n\"\n",
    "        for causal in self.causal[:3]:\n",
    "            if causal['causal_paths']:\n",
    "                for path_info in causal['causal_paths'][:1]:\n",
    "                    path_str = ' → '.join(path_info['path'][:4])\n",
    "                    if len(path_info['path']) > 4:\n",
    "                        path_str += ' ...'\n",
    "                    causal_text += f\"• {path_str}\\n\"\n",
    "        \n",
    "        ax3.text(0.1, 0.5, causal_text, fontsize=10, family='monospace',\n",
    "                verticalalignment='center')\n",
    "        \n",
    "        # 4. Recommendations (bottom)\n",
    "        ax4 = fig.add_subplot(gs[2, :])\n",
    "        ax4.axis('off')\n",
    "        \n",
    "        rec_text = \"RECOMMENDED ACTIONS\\n\" + \"=\"*50 + \"\\n\"\n",
    "        if self.recommendations['immediate_actions']:\n",
    "            rec_text += \"\\nImmediate:\\n\"\n",
    "            for action in self.recommendations['immediate_actions'][:3]:\n",
    "                rec_text += f\"  • {action[:60]}...\\n\" if len(action) > 60 else f\"  • {action}\\n\"\n",
    "        \n",
    "        ax4.text(0.05, 0.5, rec_text, fontsize=10, family='monospace',\n",
    "                verticalalignment='center')\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"Saved visualization to: {save_path}\")\n",
    "        \n",
    "        return fig\n",
    "\n",
    "# ==================== DEMO EXAMPLES ====================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING DEMO EXPLANATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create explainer instance\n",
    "explainer = HybridExplainer(\n",
    "    model=model,\n",
    "    causal_graph=causal_graph,\n",
    "    feature_names=FEATURE_NAMES,\n",
    "    scaler=scaler\n",
    ")\n",
    "\n",
    "# Example 1: Use data from file if available\n",
    "if df is not None and len(df) > 0:\n",
    "    print(\"\\nGenerating explanations for sample alerts...\")\n",
    "    \n",
    "    # Ensure we have all required features\n",
    "    available_features = [f for f in FEATURE_NAMES if f in df.columns]\n",
    "    print(f\"Available features: {len(available_features)}/{len(FEATURE_NAMES)}\")\n",
    "    \n",
    "    if len(available_features) < len(FEATURE_NAMES):\n",
    "        print(\"⚠ Warning: Not all features available. Creating synthetic example...\")\n",
    "        df = None\n",
    "    else:\n",
    "        # Select a few interesting samples\n",
    "        sample_indices = [0, 100, 500]\n",
    "        \n",
    "        for idx in sample_indices:\n",
    "            if idx >= len(df):\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"EXAMPLE ALERT #{idx}\")\n",
    "            print(f\"{'='*70}\")\n",
    "            \n",
    "            # Get alert data (all 42 features)\n",
    "            alert_row = df.iloc[idx]\n",
    "            alert_features = alert_row[FEATURE_NAMES].values\n",
    "            \n",
    "            # Generate explanation\n",
    "            explanation = explainer.explain(alert_features, alert_id=idx)\n",
    "            \n",
    "            # Print text explanation\n",
    "            print(explanation.to_text())\n",
    "            \n",
    "            # Save JSON\n",
    "            json_path = f'hybrid_explanation_{idx}.json'\n",
    "            explanation.to_json(json_path)\n",
    "            print(f\"\\nSaved JSON to: {json_path}\")\n",
    "            \n",
    "            # Save visualization\n",
    "            viz_path = f'hybrid_explanation_{idx}.png'\n",
    "            explanation.visualize(save_path=viz_path)\n",
    "            plt.close()\n",
    "\n",
    "if df is None:\n",
    "    print(\"\\n⚠ No data available for demo. Creating synthetic example...\")\n",
    "    \n",
    "    # Create synthetic alert with ALL 42 features\n",
    "    synthetic_alert = {f: 0.0 for f in FEATURE_NAMES}\n",
    "    \n",
    "    # Set specific values for key features (SSH brute force scenario)\n",
    "    synthetic_alert.update({\n",
    "        'SignatureMatchesPerDay': 5000,\n",
    "        'Similarity': 0.88,\n",
    "        'SCAS': 1.0,\n",
    "        'SignatureID': 2001219,\n",
    "        'SignatureIDSimilarity': 0.92,\n",
    "        'Proto': 6,\n",
    "        'AlertCount': 250,\n",
    "        'IntPort': 22,\n",
    "        'ExtPort': 54321,\n",
    "        'ProtoSimilarity': 1.0\n",
    "    })\n",
    "    \n",
    "    explanation = explainer.explain(synthetic_alert, alert_id=\"DEMO-001\")\n",
    "    print(explanation.to_text())\n",
    "    explanation.to_json('hybrid_explanation_demo.json')\n",
    "    explanation.visualize(save_path='hybrid_explanation_demo.png')\n",
    "    plt.close()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 4 COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  - hybrid_explanation_*.json (structured data)\")\n",
    "print(\"  - hybrid_explanation_*.png (visualizations)\")\n",
    "print(\"\\nNext: Step 5 - Evaluation (user study + quantitative metrics)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
